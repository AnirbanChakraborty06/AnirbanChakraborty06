{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELOCustomerLoyaltyNormalNonSparkVersion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBGwoeGeqNf1"
      },
      "source": [
        "# ELO Customer Loyalty - non-spark version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bijCDPR8qYC4"
      },
      "source": [
        "## Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2loqzN2OMFd"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c elo-merchant-category-recommendation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7cP_y-xO4fH"
      },
      "source": [
        "!unzip historical_transactions.csv.zip\n",
        "!unzip merchants.csv.zip\n",
        "!unzip new_merchant_transactions.csv.zip\n",
        "!unzip sample_submission.csv.zip\n",
        "!unzip test.csv.zip\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSijRxy2qg89"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmXKy2zdOxmr"
      },
      "source": [
        "import gc\n",
        "import time\n",
        "from datetime import date, datetime\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold, cross_val_score, cross_validate, train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import randint, uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8XdIDoiqjhK"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_E7AIl-O-b-"
      },
      "source": [
        "# Taken from https://www.kaggle.com/fabiendaniel/elo-world\n",
        "\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "  '''\n",
        "    An utility to reduce the memory of pandas dataframes by converting the columns \n",
        "    of numeric datatypes to lower sizes without losing any information, \n",
        "    based on the range of values in the column.\n",
        "  '''\n",
        "\n",
        "  numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "  start_mem = df.memory_usage().sum() / 1024**2    \n",
        "  for col in df.columns:\n",
        "      col_type = df[col].dtypes\n",
        "      if col_type in numerics:\n",
        "          c_min = df[col].min()\n",
        "          c_max = df[col].max()\n",
        "          if str(col_type)[:3] == 'int':\n",
        "              if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                  df[col] = df[col].astype(np.int8)\n",
        "              elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                  df[col] = df[col].astype(np.int16)\n",
        "              elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                  df[col] = df[col].astype(np.int32)\n",
        "              elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                  df[col] = df[col].astype(np.int64)  \n",
        "          else:\n",
        "              if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                  df[col] = df[col].astype(np.float16)\n",
        "              elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float64)    \n",
        "  end_mem = df.memory_usage().sum() / 1024**2\n",
        "  if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dWjA04ZPDb-"
      },
      "source": [
        "def pandas_random_forest_regr(pdf, excl_cols=['card_id'], target='target', num_of_folds=5, scoring_metric='neg_mean_squared_error', n_jobs=1):\n",
        "  '''\n",
        "      Takes in a pandas dataframe pdf and fits a random forest regressor to\n",
        "      it using K-fold cross-validation.\n",
        "\n",
        "      It returns the list of cross-validation scores.\n",
        "\n",
        "      excl_cols: ignore the columns in excl_cols that are in pdf\n",
        "      target: column in pdf to use a target\n",
        "              features = pdf.columns - excl_cols - target\n",
        "      num_of_folds: no of folds to use for K-fold cross-validation\n",
        "      scoring_metric: metric to use in cross-validation scoring\n",
        "  '''\n",
        "  non_feature_cols = excl_cols+[target]\n",
        "  feature_cols = [col for col in pdf.columns if col not in non_feature_cols]\n",
        "\n",
        "  X,y = pdf[feature_cols], pdf[target]\n",
        "\n",
        "  random_forest_regressor = RandomForestRegressor()\n",
        "  cvfolds = KFold(n_splits=num_of_folds)\n",
        "\n",
        "  return cross_val_score(estimator=random_forest_regressor,X=X,y=y,cv=cvfolds,scoring=scoring_metric, verbose=3, n_jobs=n_jobs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFc3DqVitySx"
      },
      "source": [
        "def proportion_feature_generator(df_source, col, df_target, col_name_prefix, key_col = 'card_id'):\n",
        "  '''\n",
        "      There are categorical columns in histTxns where we would want to derive\n",
        "      the proportion of trasactions belonging to each category. This utility\n",
        "      - takes as input the transaction data containing dataframe df_source,\n",
        "      - derives the category-wise proportion for the column col in df_source for\n",
        "        each value of key_col \n",
        "      - and merges it with df_target, the dataframe that contains\n",
        "        the new features.\n",
        "      The column names of the proportion features are decided from col_name_prefix\n",
        "      appended with _{value of the category}.\n",
        "  '''\n",
        "  \n",
        "  col_name = lambda val: col_name_prefix + '_' + str(val)\n",
        "\n",
        "  groupwise_count = df_source.groupby(key_col, sort=False)[col].value_counts(normalize=True, sort=False).unstack(level=-1, fill_value=0.0).\\\n",
        "                    rename(columns=col_name)\n",
        "\n",
        "  return df_target.merge(groupwise_count, how='left', on=key_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndUstWn1OEB7"
      },
      "source": [
        "def proportions(g, n, col, group_by, entry_col_name, proportion_col_name):\n",
        "\n",
        "  dataframes = []\n",
        "\n",
        "  for i in range(n):\n",
        "    dataframes.append(g.iloc[i:i+1].reset_index(level=col, name=proportion_col_name+str(i+1)).rename(columns={col:entry_col_name+str(i+1)}))\n",
        "    # g2 = g.iloc[1:2].reset_index(level='city', name='2Prop').rename(columns={'city':'city2'})\n",
        "    # g3 = g.iloc[2:3].reset_index(level='city', name='3Prop').rename(columns={'city':'city3'})\n",
        "\n",
        "  return reduce(lambda  left,right: pd.merge(left,right,on=group_by, how='outer'), dataframes)\n",
        "\n",
        "def top_n_entries_and_proportion(df, n, col, entry_col_name_prefix, proportion_col_name_prefix, df_target, group_by='card_id'):\n",
        "\n",
        "  s = df.groupby(group_by, sort=False)[col].value_counts(normalize=True, sort=False).groupby(level=0, group_keys=False, sort=False).nlargest(n=n)\n",
        "  new_df = s.groupby(level=group_by, group_keys=False, sort=False).apply(proportions, n, col, group_by, entry_col_name_prefix, proportion_col_name_prefix).fillna(0.0)\n",
        "  return df_target.merge(new_df, how='left', on=group_by)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDZ0efeOtMJh"
      },
      "source": [
        "def top_n_entries_and_proportion_modified(df, n, col, entry_col_name_prefix, proportion_col_name_prefix, df_target, group_by='card_id'):\n",
        "    \n",
        "    value_counts_start_time = time.time()\n",
        "    dataframes = []\n",
        "    d_all = df.groupby(group_by, sort=False)[col].value_counts(normalize=True, sort=False).groupby(level=0, group_keys=False, sort=False).nlargest(n).reset_index(level=col, name='prop')\n",
        "    for i in range(n):\n",
        "        d = d_all.groupby(level=0, group_keys=False, sort=False).nth(i).rename(columns={col:entry_col_name_prefix+str(i+1), 'prop':proportion_col_name_prefix+str(i+1)})\n",
        "        dataframes.append(d)\n",
        "\n",
        "    new_df = reduce(lambda  left,right: pd.merge(left,right,on=group_by, how='outer'), dataframes)\n",
        "    fillna_dict = {col_name:(0.0 if proportion_col_name_prefix in col_name else 9999) for col_name in new_df.columns}\n",
        "    new_df.fillna(fillna_dict, inplace=True)\n",
        "    value_counts_end_time = time.time()\n",
        "    print(f'Value counts time = {round(value_counts_end_time - value_counts_start_time, 3)}')\n",
        "    return df_target.merge(new_df, how='left', on=group_by)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAuZ_H0p-XYj"
      },
      "source": [
        "def plot_feature_importance(df, exclude_cols=['card_id'], target='target', test_size=0.25, num_of_folds=None, estimator_verbosity=2,\n",
        "                            cv_verbosity=2, cv_scoring='neg_mean_squared_error', min_samples_split=10, max_features=0.5):\n",
        "  '''\n",
        "      Takes in a pandas dataframe df and finds the feature importance.\n",
        "\n",
        "      excl_cols: ignore the columns in excl_cols that are in df\n",
        "      target: column in df to use a target\n",
        "              features = df.columns - excl_cols - target\n",
        "      test_size: Feature importance can be calculated over a certain fraction of the\n",
        "                  train set. In that case the hold out set size.\n",
        "      num_of_folds: Feature importance cane be calculated by performing cross-validation. \n",
        "                    No of folds to use for K-fold cross-validation in such cases.\n",
        "      estimator_verbosity: verbosity level of the random forest estimator.\n",
        "      cv_verbosity: verbosity level of cross_validate, if it is used.\n",
        "      cv_scoring: scoring method in cross_validate, if it is used.\n",
        "  '''\n",
        "\n",
        "  feature_cols = [x for x in set(df.columns)-set((*exclude_cols,target))]\n",
        "\n",
        "  random_forest = RandomForestRegressor(min_samples_split=min_samples_split, max_features=max_features, verbose=estimator_verbosity)\n",
        "\n",
        "  if num_of_folds is None:\n",
        "    # follow hold out set approach\n",
        "    df_train, *_ = train_test_split(df, test_size=test_size)\n",
        "    random_forest.fit(df_train[feature_cols], df_train[target])\n",
        "    feature_importance_std_errors = np.std([tree.feature_importances_ for tree in random_forest.estimators_], axis=0)\n",
        "    feature_importances = pd.Series(random_forest.feature_importances_, index=feature_cols).sort_values(ascending=True)\n",
        "    output = (feature_importances, feature_importance_std_errors,random_forest)\n",
        "  \n",
        "  else:\n",
        "    # follow cross-validation approach\n",
        "    cvfolds = KFold(n_splits=num_of_folds)\n",
        "    results = cross_validate(estimator=random_forest, X=df[feature_cols], y=df[target], scoring=cv_scoring, \n",
        "                             cv=cvfolds, verbose=cv_verbosity, return_estimator=True)\n",
        "    feature_importances = np.array([rf.feature_importances_ for rf in results['estimator']]).mean(axis=0)\n",
        "    feature_importances = pd.Series(feature_importances, index=feature_cols).sort_values(ascending=True)\n",
        "    feature_importance_std_errors = np.mean([\n",
        "                                     np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
        "                                     for rf in results['estimator']\n",
        "                                     ], axis=0)\n",
        "    output = (feature_importances, feature_importance_std_errors,results)\n",
        "  \n",
        "\n",
        "  # plotting the feature importances\n",
        "  fig, ax = plt.subplots(figsize=(10,25))\n",
        "  feature_importances.plot(kind='barh', ax=ax, xlabel='importance_scores', ylabel='features', yerr=feature_importance_std_errors)\n",
        "\n",
        "  return output                            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALuiKZgwPYoQ"
      },
      "source": [
        "def get_days_diff_and_merge(df, s1, s2, diff_col_name, key_col='card_id'):\n",
        "  '''\n",
        "      Takes 2 series/timestamp objects - s1 and s2 - calculates the days difference\n",
        "      between them and merges(left) the result with df using key_col.\n",
        "\n",
        "      The days difference column name becomes diff_col_name.\n",
        "  '''\n",
        "  s_diff = (s1-s2).dt.days.rename(diff_col_name)\n",
        "  return df.merge(s_diff, how='left', on=key_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agpsyVDpqnQV"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBNqcR_JqtiJ"
      },
      "source": [
        "### histTxns and newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atsbm-kCPLti",
        "outputId": "f9604ad5-e430-456d-f333-3d951b2b8e88"
      },
      "source": [
        "histTxns = pd.read_csv('historical_transactions.csv', header=0)\n",
        "histTxns = reduce_mem_usage(df=histTxns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 1749.11 Mb (43.7% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht-E_cAigXC8",
        "outputId": "cfd15c67-aa49-46cb-c20b-5f3ee7426f77"
      },
      "source": [
        "newTxns = pd.read_csv('new_merchant_transactions.csv', header=0)\n",
        "newTxns = reduce_mem_usage(df=newTxns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 114.20 Mb (45.5% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bysRY0jU44E"
      },
      "source": [
        "# histTxns.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdKX9nUcLMDI"
      },
      "source": [
        "# histTxns.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWpmsjdcgj9O"
      },
      "source": [
        "# newTxns.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Wyw0dnVypF"
      },
      "source": [
        "We would like to do null imputation for **category_3, category_2 and merchant_id** respectively. Hence we need to appropriately encode the columns of histTxns and newTxns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBRNyIC0feAU"
      },
      "source": [
        "#### Encoding categoricals in histTxns and newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sziA8OGQVBaF"
      },
      "source": [
        "# histTxns[['merchant_id','category_3','category_2']].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxiEMaDPW1Go"
      },
      "source": [
        "We leave merchant_id as it is for now because it has too many unique types and given the number of records in histTxns, imputation algorithms will be unable to handle them in the available RAM. **Besides, it seems that a feature with so many unique types will possibly not have any generalization capability.** \n",
        "\n",
        "**The idea is that we cannot expect someone to just predict the loyalty score from only the card_id because it is too varying to possibly account for any generalizations.**\n",
        "\n",
        "Also we have the assumption that newTxns contains transactions for a card_id with merchant_ids that are not present in histTxns. This assumption we will be verifying. This assumption might get disturbed if we use null imputation in merchant_id column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6eNoeqMoQAZ"
      },
      "source": [
        "<a name=\"looping_approach\"></a>\n",
        "One point to note regarding the way ordinal encoding is done here -\n",
        "\n",
        "\n",
        "\n",
        "> Instead of encoding multiple columns at once we encode one column at a time. This to ensure that we can stay within the RAM capacity. Let us call this the \"**looping approach**\" and will be used later as well when we work with histTxns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCuhdge-IFK2",
        "outputId": "15d3f945-5de3-462b-eb48-d07f9e505958"
      },
      "source": [
        "null_hist_categorical_features = ['category_3','category_2']\n",
        "null_hist_categorical_encoders = {}\n",
        "for feature in null_hist_categorical_features:\n",
        "  start_time = time.time()\n",
        "  null_hist_categorical_encoders[feature] = OrdinalEncoder()\n",
        "  null_hist_categorical_encoders[feature].fit(np.concatenate((histTxns[feature].dropna().unique(), newTxns[feature].dropna().unique())).reshape(-1,1))\n",
        "  histTxns.loc[histTxns[feature].notna(), [feature]] = null_hist_categorical_encoders[feature].transform(histTxns.loc[histTxns[feature].notna(), [feature]])\n",
        "  newTxns.loc[newTxns[feature].notna(), [feature]] = null_hist_categorical_encoders[feature].transform(newTxns.loc[newTxns[feature].notna(), [feature]])\n",
        "  time_taken = round(time.time() - start_time, 1)\n",
        "  print(f'{feature} encoding completed in {time_taken} seconds')\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category_3 encoding completed in 20.6 seconds\n",
            "category_2 encoding completed in 14.9 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-XvD2XwE21w",
        "outputId": "07c94af3-7d07-4f4a-ed50-67d0b8b6009c"
      },
      "source": [
        "nonnull_hist_categorical_features = [x for x in histTxns.columns if x not in ('installments','month_lag','purchase_amount','category_3','merchant_id','category_2','card_id','purchase_date')]\n",
        "nonnull_hist_categorical_encoders = {}\n",
        "for feature in nonnull_hist_categorical_features:\n",
        "  start_time = time.time()\n",
        "  nonnull_hist_categorical_encoders[feature] = OrdinalEncoder()\n",
        "  nonnull_hist_categorical_encoders[feature].fit(np.concatenate((histTxns[feature].unique(), newTxns[feature].unique())).reshape(-1,1))\n",
        "  histTxns.loc[:,[feature]] = nonnull_hist_categorical_encoders[feature].transform(histTxns.loc[:,[feature]])\n",
        "  newTxns.loc[:,[feature]] = nonnull_hist_categorical_encoders[feature].transform(newTxns.loc[:,[feature]])\n",
        "  time_taken = round(time.time() - start_time, 1)\n",
        "  print(f'{feature} encoding completed in {time_taken} seconds')\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "authorized_flag encoding completed in 14.5 seconds\n",
            "city_id encoding completed in 7.3 seconds\n",
            "category_1 encoding completed in 14.2 seconds\n",
            "merchant_category_id encoding completed in 8.8 seconds\n",
            "state_id encoding completed in 7.1 seconds\n",
            "subsector_id encoding completed in 9.1 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlcWYuQ97Tr8"
      },
      "source": [
        "# histTxns.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krr2Hi_j7fb6"
      },
      "source": [
        "histTxns['category_3'] = histTxns['category_3'].astype('float16')\n",
        "newTxns['category_3'] = newTxns['category_3'].astype('float16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbJPnOmRxZgi"
      },
      "source": [
        "histTxns['purchase_date'] = histTxns['purchase_date'].astype('datetime64[ns]')\n",
        "newTxns['purchase_date'] = newTxns['purchase_date'].astype('datetime64[ns]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGT1soFeQ9dR",
        "outputId": "977fe01d-7569-4b62-cb63-c3775634e170"
      },
      "source": [
        "histTxns = reduce_mem_usage(df=histTxns)\n",
        "newTxns = reduce_mem_usage(df=newTxns)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 1304.89 Mb (43.4% reduction)\n",
            "Mem. usage decreased to 84.24 Mb (44.4% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI8nKlqXrFbN"
      },
      "source": [
        "#### Imputing null values in histTxns and newTxns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w38atC3NdRqC"
      },
      "source": [
        "To proceed with the imputation we will have to take a few measures because of the dataset size -\n",
        "\n",
        "1. We will not be able to use IteratorImputer or any multivariate imputer from sklearn.\n",
        "2. Rather than fitting a model where *imputation eligible features* are dependant on all other features we will use their dependancy on only a few features. These **few** will be decided based on the f-regression scores. We would have preferred to use some non-linear relation identifier like mutual-information score. However that will not be feasible for this size of data.\n",
        "3. The f-scores will not be found in the usual way; we will use the \"looping approach\" referred to [here](#looping_approach)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKIUaIQ_Y8rB"
      },
      "source": [
        "# hist_f_score_matrix = pd.DataFrame(np.zeros((6,4)), index=('authorized_flag','city_id','category_1','merchant_category_id','state_id','subsector_id'), \n",
        "#                                   columns=pd.MultiIndex.from_product([('category_3','category_2'),('f_score','p_value')]))\n",
        "# for null_feature in hist_f_score_matrix.columns.levels[0]:\n",
        "#   for nonnull_feature in hist_f_score_matrix.index:\n",
        "#     f_score, p_value = f_regression(histTxns[histTxns[null_feature].notna()][[nonnull_feature]],histTxns[histTxns[null_feature].notna()][null_feature])\n",
        "#     hist_f_score_matrix.loc[nonnull_feature,(null_feature,'f_score')] = round(f_score[0],3)\n",
        "#     hist_f_score_matrix.loc[nonnull_feature,(null_feature,'p_value')] = round(p_value[0],4)\n",
        "#     print(f'{null_feature}, {nonnull_feature}:    Done')\n",
        "#     gc.collect()\n",
        "# hist_f_score_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WAlv6Gvr9Wj"
      },
      "source": [
        "The f-scores are all almost 0. So we finally choose to fill the null values in the respective columns randomly using the existing value-wise proportions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YUol6Gporjc",
        "outputId": "7f384ab0-c0ce-40bf-8278-fffa780ea54d"
      },
      "source": [
        "for null_feature in ('category_3','category_2'):\n",
        "  no_of_na_entries = histTxns[histTxns[null_feature].isna()].shape[0]\n",
        "  s = histTxns[histTxns[null_feature].notna()][null_feature].value_counts(normalize=True, sort=False)\n",
        "  histTxns.loc[histTxns[null_feature].isna(), null_feature] = np.random.choice(a=s.index, size=no_of_na_entries, p=s.values)\n",
        "  print(f'{null_feature} imputation completed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category_3 imputation completed.\n",
            "category_2 imputation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJv5zD9arEWT",
        "outputId": "bfb6b41d-ac42-48d5-974e-8b822546c998"
      },
      "source": [
        "for null_feature in ('category_3','category_2'):\n",
        "  no_of_na_entries = newTxns[newTxns[null_feature].isna()].shape[0]\n",
        "  s = newTxns[newTxns[null_feature].notna()][null_feature].value_counts(normalize=True, sort=False)\n",
        "  newTxns.loc[newTxns[null_feature].isna(), null_feature] = np.random.choice(a=s.index, size=no_of_na_entries, p=s.values)\n",
        "  print(f'{null_feature} imputation completed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category_3 imputation completed.\n",
            "category_2 imputation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxOFLRIErVSy",
        "outputId": "ea9fb48e-c9fa-4785-e4f3-7c08f6730512"
      },
      "source": [
        "del s\n",
        "del no_of_na_entries\n",
        "histTxns = reduce_mem_usage(df=histTxns)\n",
        "newTxns = reduce_mem_usage(df=newTxns)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 1304.89 Mb (0.0% reduction)\n",
            "Mem. usage decreased to 84.24 Mb (0.0% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcjSHyDJrRhx"
      },
      "source": [
        "# histTxns.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-15cuAshraYC"
      },
      "source": [
        "# newTxns.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_odIVU76rrMZ"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVYk2y_8PV9c",
        "outputId": "e8758a6a-99e7-48ec-c717-b53c53f66594"
      },
      "source": [
        "train = pd.read_csv('train.csv', header=0)\n",
        "train = reduce_mem_usage(df=train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRkpU0QXwFj_"
      },
      "source": [
        "# train.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM7-vsjTwsSA",
        "outputId": "0f2f0b15-cfba-41aa-af21-7ed087625cb4"
      },
      "source": [
        "train['first_active_month'] = train['first_active_month'].astype('datetime64[ns]')\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8LWX2_9sygq"
      },
      "source": [
        "### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3HgShX7rzhs",
        "outputId": "29fbdcea-b22e-4203-de6c-032246bcceab"
      },
      "source": [
        "test = pd.read_csv('test.csv', header=0)\n",
        "test = reduce_mem_usage(df=test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BXk2Dh_yE57"
      },
      "source": [
        "test['first_active_month'] = test['first_active_month'].astype('datetime64[ns]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vZQyiuQx6Yv"
      },
      "source": [
        "# test.isna().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8lW-rBH70xh"
      },
      "source": [
        "#### Null imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "dWeI-mZdQalB",
        "outputId": "a00a5c56-774c-40f3-db52-a8860c716c65"
      },
      "source": [
        "test[test['first_active_month'].isna()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_active_month</th>\n",
              "      <th>card_id</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11578</th>\n",
              "      <td>NaT</td>\n",
              "      <td>C_ID_c27b4f80f7</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      first_active_month          card_id  feature_1  feature_2  feature_3\n",
              "11578                NaT  C_ID_c27b4f80f7          5          2          1"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr-bghD37zsB"
      },
      "source": [
        "test.loc[test[test['first_active_month'].isna()].index, 'first_active_month'] = histTxns[histTxns['card_id']=='C_ID_c27b4f80f7']['purchase_date'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLBcdlgds09Q"
      },
      "source": [
        "### new_features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd8-hpaqrzhs",
        "outputId": "ff4b33d2-bd7d-4c3d-8594-cf216ee615ca"
      },
      "source": [
        "new_features = pd.read_csv('new_features_01102021_03_54.csv', header=0)\n",
        "new_features = reduce_mem_usage(df=new_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 62.40 Mb (73.8% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ef7rkoZ7_Hr"
      },
      "source": [
        "## Sanity checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjIsUqb58D5k"
      },
      "source": [
        "### Check 1: Exclusivity of histTxns and newTxns\n",
        "\n",
        "**Is it true that newTxns only contains the transactions for a card_id with merchant_ids that were not present in histTxns?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL6JgjOx2iOH"
      },
      "source": [
        "# len(histTxns[['card_id','merchant_id']].drop_duplicates().merge(\n",
        "#       newTxns[['card_id','merchant_id']].drop_duplicates()\n",
        "#       ))\n",
        "# ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejvmDIzrtl03"
      },
      "source": [
        "## Creating new features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZvZGeDe9DUM"
      },
      "source": [
        "### Transaction count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOQ15fP89GNS"
      },
      "source": [
        "# nonnull_hist_categorical_encoders['authorized_flag'].categories_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeYSDgN49leN"
      },
      "source": [
        "#### newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpr4J1s0ADvj"
      },
      "source": [
        "# newTxns['authorized_flag'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff8vwO-sA5PL"
      },
      "source": [
        "There are only authorised transactions in newTxns. Hence no need to worry about authorised-unauthorised divide like in histTxns; only transaction count will do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F70_DBKrBMva",
        "outputId": "88f5a2bc-42cb-44bd-dc9f-ac698935dea3"
      },
      "source": [
        "new_features = new_features.merge(newTxns.groupby('card_id')['authorized_flag'].count(), how='left', on='card_id').\\\n",
        "rename(columns={'authorized_flag':'newTxnCnt'}).\\\n",
        "fillna(value={'newTxnCnt':0.0})\n",
        "\n",
        "new_features = reduce_mem_usage(df=new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 48.12 Mb (3.7% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT4hTLmFLhSR"
      },
      "source": [
        "### Purchase amounts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v0vcVE4Lld3"
      },
      "source": [
        "#### newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ri3PyCULnn7",
        "outputId": "dc288df6-c665-4ed7-9b39-53046cc0f97f"
      },
      "source": [
        "new_features = new_features.merge(\n",
        "          newTxns.groupby('card_id')['purchase_amount'].agg([np.mean, np.std]).\\\n",
        "            rename(columns={'mean':'newAvgPurchaseAmt', 'std':'newSTDPurchaseAmt'}), \n",
        "          how='left', \n",
        "          on='card_id').\\\n",
        "    fillna(value={'newAvgPurchaseAmt':0.0, 'newSTDPurchaseAmt':0.0})\n",
        "\n",
        "new_features = reduce_mem_usage(df=new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 49.36 Mb (3.6% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFwPhuZsb_VY"
      },
      "source": [
        "### category_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK-PdXuNcDB0"
      },
      "source": [
        "#### newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNrE_EeQcS_A",
        "outputId": "33e57787-a6b7-4124-897a-20509ca9d126"
      },
      "source": [
        "nonnull_hist_categorical_encoders['category_1'].categories_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['N', 'Y'], dtype=object)]"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1iLEAFUodRa"
      },
      "source": [
        "new_features = new_features.merge(\n",
        "            newTxns.groupby('card_id', sort=False)['category_1'].value_counts(normalize=True, sort=False)\\\n",
        "            .unstack(level=-1, fill_value=0.0)\\\n",
        "            .rename(columns = {0.0:'N', 1.0:'newCategory1YProp'})\\\n",
        "            .drop('N', axis=1),\n",
        "    on = 'card_id',\n",
        "    how = 'left'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OikKoROxRUu",
        "outputId": "4248815f-ded9-4943-ef3e-bb163d68b641"
      },
      "source": [
        "new_features.loc[new_features.newCategory1YProp.isna(), 'newCategory1YProp'] = new_features.loc[new_features.newCategory1YProp.isna(),'histCategory1YProp']\n",
        "\n",
        "new_features = reduce_mem_usage(df=new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 64.89 Mb (2.8% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2156"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftvi5YyFtttA"
      },
      "source": [
        "### category_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18_rG7xLdMBv"
      },
      "source": [
        "#### histTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JVoK32Omrzhs",
        "outputId": "c07f3110-2243-4b89-a034-60b159b44ffe"
      },
      "source": [
        "plt.boxplot(histTxns.groupby('card_id').category_2.nunique(), patch_artist=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm77S9w-t4o4"
      },
      "source": [
        "There are 5 different categories and the card_ids have number of different category_2 values ranging from 1-5. Therefore we introduce 5 features for the proportion of transactions belonging to each category.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DwVeLC4Ru8O"
      },
      "source": [
        "# new_features = proportion_feature_generator(histTxns, 'category_2', new_features, 'histCategory2Prop')\n",
        "# new_features = reduce_mem_usage(new_features)\n",
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkDzUOE9UhEZ"
      },
      "source": [
        "# null_hist_categorical_encoders['category_2'].categories_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOpSw3bKSdKT"
      },
      "source": [
        "# new_features.rename(columns={'histCategory2Prop_0.0':'histCategory2Prop_1',\n",
        "#                              'histCategory2Prop_1.0':'histCategory2Prop_2',\n",
        "#                              'histCategory2Prop_2.0':'histCategory2Prop_3',\n",
        "#                              'histCategory2Prop_3.0':'histCategory2Prop_4',\n",
        "#                              'histCategory2Prop_4.0':'histCategory2Prop_5'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dyxvNDOdaVu"
      },
      "source": [
        "#### newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "KLyzYnQQdc8_",
        "outputId": "ca7f5551-fd1e-48d4-857a-130ab0fb878c"
      },
      "source": [
        "plt.boxplot(newTxns.groupby('card_id').category_2.nunique(), patch_artist=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp9zTlq2eKqj",
        "outputId": "145f8d64-2290-4ed4-ae10-ac728c5d083c"
      },
      "source": [
        "new_features = proportion_feature_generator(newTxns, 'category_2', new_features, 'newCategory2Prop')\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 62.40 Mb (13.0% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9947"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIpjKJIReUmL"
      },
      "source": [
        "new_features.rename(columns={'newCategory2Prop_0.0':'newCategory2Prop_1',\n",
        "                             'newCategory2Prop_1.0':'newCategory2Prop_2',\n",
        "                             'newCategory2Prop_2.0':'newCategory2Prop_3',\n",
        "                             'newCategory2Prop_3.0':'newCategory2Prop_4',\n",
        "                             'newCategory2Prop_4.0':'newCategory2Prop_5'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq9FVP5yvIkZ"
      },
      "source": [
        "new_features.fillna(\n",
        "    value = {\n",
        "        'newCategory2Prop_1': 0.0,\n",
        "        'newCategory2Prop_2': 0.0,\n",
        "        'newCategory2Prop_3': 0.0,\n",
        "        'newCategory2Prop_4': 0.0,\n",
        "        'newCategory2Prop_5': 0.0\n",
        "    },\n",
        "    inplace = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1Zflol9fvy3"
      },
      "source": [
        "### category_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vhnEZxjf0YJ"
      },
      "source": [
        "#### newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJZ8vSkJf5bU",
        "outputId": "0423adf0-70c5-4609-9939-3912ba9bc702"
      },
      "source": [
        "new_features = proportion_feature_generator(newTxns, 'category_3', new_features, 'newCategory3Prop')\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 64.27 Mb (8.0% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZfnxKLugJwT",
        "outputId": "3cfcee30-539b-4724-f48c-62b5fbbd59ec"
      },
      "source": [
        "null_hist_categorical_encoders['category_3'].categories_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array(['A', 'B', 'C'], dtype=object)]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXp5ZlMngPLc"
      },
      "source": [
        "new_features.rename(columns={'newCategory3Prop_0.0':'newCategory3Prop_A',\n",
        "                             'newCategory3Prop_1.0':'newCategory3Prop_B',\n",
        "                             'newCategory3Prop_2.0':'newCategory3Prop_C'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fQbBXfIu9r6"
      },
      "source": [
        "new_features.fillna(\n",
        "    value = {\n",
        "        'newCategory3Prop_A': 0.0,\n",
        "        'newCategory3Prop_B': 0.0,\n",
        "        'newCategory3Prop_C': 0.0\n",
        "    },\n",
        "    inplace = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "non7LVP0U4X3"
      },
      "source": [
        "### state_id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHeFnWCnO7fQ"
      },
      "source": [
        "# len(nonnull_hist_categorical_encoders['state_id'].categories_[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQEMX2KdVFQV"
      },
      "source": [
        "# plt.boxplot(histTxns.groupby('card_id').state_id.nunique(), patch_artist=True, showfliers=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9R5NyvZfNdr"
      },
      "source": [
        "Given the number of unique state_ids and the box-plot above denoting the average number of state_ids per card_id, we decide to introduce features corresponding to the top 3 state_ids and their respective proportions for each card_id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thCXQnaT5k4F"
      },
      "source": [
        "# new_features.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU1PLLWJMo5x"
      },
      "source": [
        "# new_features = top_n_entries_and_proportion_modified(histTxns, 3, 'state_id', 'histStateId', 'histStateIdProp', new_features, group_by='card_id')\n",
        "# new_features = reduce_mem_usage(new_features)\n",
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJEp1FufNomF"
      },
      "source": [
        "### subsector_id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tq_4Te3Pfgw"
      },
      "source": [
        "# len(nonnull_hist_categorical_encoders['subsector_id'].categories_[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heO1K1SKNuiH"
      },
      "source": [
        "# plt.boxplot(histTxns.groupby('card_id').subsector_id.nunique(), patch_artist=True, showfliers=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTVt5FBGNySj"
      },
      "source": [
        "# new_features = top_n_entries_and_proportion_modified(histTxns, 3, 'subsector_id', 'histSubsectorId', 'histSubsectorIdProp', new_features, group_by='card_id')\n",
        "# new_features = reduce_mem_usage(new_features)\n",
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfJiKuoPOi8E"
      },
      "source": [
        "### merchant_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYEOW2Hkzypk"
      },
      "source": [
        "#### newTxns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8VCJK9x-Q7G"
      },
      "source": [
        "We want to find the number of distinct new merchant_ids visited by each card_id. Because there are no common (card_id, merchant_id) combinations in histTxns and newTxns -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XUIlt4K0OKU",
        "outputId": "bc52b4ea-0314-4d59-b337-3e8867371675"
      },
      "source": [
        "new_features = new_features.merge(\n",
        "    newTxns[['card_id','merchant_id']].dropna().drop_duplicates().groupby('card_id')['merchant_id'].count().rename('newMerchantIDCnt'),\n",
        "    how = 'left',\n",
        "    on = 'card_id'\n",
        ").fillna(value={'newMerchantIDCnt':0})\n",
        "\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 52.47 Mb (3.4% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "321"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgHWdfsdOnmG"
      },
      "source": [
        "### merchant_category_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sSZ7XClz89V"
      },
      "source": [
        "#### histTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5deHNBsPoG5"
      },
      "source": [
        "# len(nonnull_hist_categorical_encoders['merchant_category_id'].categories_[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shJjzzoROsI0"
      },
      "source": [
        "# plt.boxplot(histTxns.groupby('card_id').merchant_category_id.nunique(), patch_artist=True, showfliers=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlbNVDnLOwMa"
      },
      "source": [
        "# new_features = top_n_entries_and_proportion_modified(histTxns, 5, 'merchant_category_id', 'histMerchantCategoryID', 'histMerchantCategoryIDProp', new_features, group_by='card_id')\n",
        "# new_features = reduce_mem_usage(new_features)\n",
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjt_HmnD0A6B"
      },
      "source": [
        "#### newTxns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGlcE7yE0EQE"
      },
      "source": [
        "new_merchantCatId_df = newTxns[['card_id','merchant_category_id']].drop_duplicates().merge(\n",
        "    histTxns[['card_id','merchant_category_id']].drop_duplicates(),\n",
        "    how = 'left',\n",
        "    indicator = True\n",
        ")\\\n",
        ".query(\"_merge == 'left_only' \")\\\n",
        ".drop('_merge', axis=1)\\\n",
        ".reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_PtcLWXJc3i",
        "outputId": "96fff607-47e9-4b6f-b9e3-e84d2c455741"
      },
      "source": [
        "new_features = new_features.merge(\n",
        "    new_merchantCatId_df.groupby('card_id')['merchant_category_id'].count().rename('newMerchantCategoryIDCnt'),\n",
        "    on = 'card_id',\n",
        "    how = 'left'\n",
        ").fillna(value = {'newMerchantCategoryIDCnt':0})\n",
        "\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 53.09 Mb (3.4% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1345"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO5ugre0Qvhl"
      },
      "source": [
        "We will check if the proportion of the most frequent merchant categories also changes with change in merchant_ids and by how much."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zebFkRGkQSV_",
        "outputId": "86c0eff7-e905-481e-f0d7-b70b46b8a32b"
      },
      "source": [
        "plt.boxplot(\n",
        "    newTxns.groupby('card_id').merchant_category_id.nunique(), \n",
        "    patch_artist=True, showfliers=False);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZVEhYW3KnM0",
        "outputId": "ecff70db-6b3c-4ef2-8230-4d55d9629e76"
      },
      "source": [
        "new_features = top_n_entries_and_proportion_modified(\n",
        "    df = newTxns,\n",
        "    n = 5,\n",
        "    col = 'merchant_category_id', \n",
        "    entry_col_name_prefix = 'newMerchantCategoryID',\n",
        "    proportion_col_name_prefix = 'newMerchantCategoryIDProp',\n",
        "    df_target = new_features \n",
        ")\n",
        "\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value counts time = 389.112\n",
            "Mem. usage decreased to 59.30 Mb (23.9% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaGqkBJZUMar"
      },
      "source": [
        "new_features.fillna(\n",
        "    value = {\n",
        "       col_name:  (0.0 if 'newMerchantCategoryIDProp' in col_name else 9999) for col_name in new_features.columns\n",
        "    },\n",
        "    inplace = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuRNHwfSPmtj"
      },
      "source": [
        "### Time dependant features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am3aTGciPqrT"
      },
      "source": [
        "#### Age of card"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCYLcah3PjI3",
        "outputId": "8889b868-9252-4e9b-fc69-a568542e5ee0"
      },
      "source": [
        "new_features = get_days_diff_and_merge(new_features, \n",
        "                        datetime.now(),\n",
        "                        pd.concat([train, test], axis=0).set_index('card_id')['first_active_month'],\n",
        "                        'card_age'\n",
        "                        )\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 49.98 Mb (3.6% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6TByIGBVmA3"
      },
      "source": [
        "#### Monthly transaction count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfIb6Uw-VtHD",
        "outputId": "ba4728ec-7201-4861-d181-910c187f2900"
      },
      "source": [
        "new_features = new_features.merge(\n",
        "    newTxns.groupby(['card_id', newTxns.purchase_date.dt.month], sort=False)['purchase_date'].count().groupby('card_id').mean().rename('newMonthlyTxnCnt'),\n",
        "    on = 'card_id',\n",
        "    how = 'left'\n",
        ").fillna(value={'newMonthlyTxnCnt':0})\n",
        "\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 50.60 Mb (3.6% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcGTxkbJuL1V"
      },
      "source": [
        "#### Monthly purchase amounts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niTSLJRqqKbQ",
        "outputId": "1e003781-1cd8-4c61-e79c-ca335d9b78a1"
      },
      "source": [
        "new_features = new_features.merge(\n",
        "    newTxns.groupby(['card_id', newTxns.purchase_date.dt.month], sort=False)['purchase_amount'].sum().groupby('card_id', sort=False).aggregate(\n",
        "        newMonthlyAvgPurchaseAmt = 'mean',\n",
        "        newMonthlySTDPurchaseAmt = 'std'\n",
        "    ),\n",
        "    on = 'card_id',\n",
        "    how = 'left'\n",
        ").fillna(value={'newMonthlyAvgPurchaseAmt':0.0, 'newMonthlySTDPurchaseAmt':0.0})\n",
        "\n",
        "new_features = reduce_mem_usage(new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 51.85 Mb (3.5% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_XCbt6_pJF7"
      },
      "source": [
        "## Feature pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfWnQn_KpNBq"
      },
      "source": [
        "### Scaling features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgz0w3o4pRsb"
      },
      "source": [
        "sc = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT_ui2YapVIp"
      },
      "source": [
        "scaling_reqd_cols = [\n",
        "              'histAuthTxnsCount', 'histUnauthTxnCount',\n",
        "              'histAvgUnauthPurchaseAmt', 'histStdevUnauthPurchaseAmt',\n",
        "              'histTotCityCount',\n",
        "              'histAvgInstallmentNo', 'histStdevInstallmentNo',\n",
        "              'histActivePeriodSpan',\n",
        "              'histAvgMonthlyAuthTxnCnt', 'histStdMonthlyAuthTxnCnt',\n",
        "              'histAvgMonthlyPurchaseAmt', 'histStdMonthlyPurchaseAmt',\n",
        "              'histAvgMonthlyUnauthTxnCnt', 'histStdMonthlyUnauthTxnCnt',\n",
        "              'histQ1TxnCnt', 'histQ2TxnCnt', 'histQ3TxnCnt', 'histQ4TxnCnt', 'histQ5TxnCnt',\n",
        "              'histQ1PurchaseAmt', 'histQ2PurchaseAmt', 'histQ3PurchaseAmt', 'histQ4PurchaseAmt', 'histQ5PurchaseAmt',\n",
        "              'newTxnCnt', \n",
        "              'card_age', \n",
        "              'newMonthlyTxnCnt', 'newMonthlyAvgPurchaseAmt', 'newMonthlySTDPurchaseAmt',\n",
        "              'newMerchantIDCnt', 'newMerchantCategoryIDCnt'\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w19gt_qspW9q",
        "outputId": "7773a078-d773-4a36-99f3-73f9fd6ea2c2"
      },
      "source": [
        "new_features.loc[:, scaling_reqd_cols] = sc.fit_transform(new_features[scaling_reqd_cols])\n",
        "\n",
        "new_features = reduce_mem_usage(df=new_features)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 61.47 Mb (48.4% reduction)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "052fWzyzp3gV"
      },
      "source": [
        "## Model fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if2qDZueqDGs"
      },
      "source": [
        "### Hyperparameter tuning and performance estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMvzR-kvs5Gn"
      },
      "source": [
        "new_features_train = new_features.merge(train[['card_id','target']], on='card_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJajHNtMs8Kf"
      },
      "source": [
        "feature_cols = [x for x in new_features_train.columns if x not in ('card_id','target')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS6Mq21MqNT8"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMNhDK3OqSV1"
      },
      "source": [
        "param_grid = {'n_estimators': randint(10,100),\n",
        "              'min_samples_split': randint(2,150),\n",
        "              'max_features': uniform(0.03,1.0)\n",
        "              }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6WqFfZxrxL0"
      },
      "source": [
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=3, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajlWfeRfrljS"
      },
      "source": [
        "regressor = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=10, cv=inner_cv, \n",
        "                         scoring='neg_root_mean_squared_error', \n",
        "                         verbose=1,\n",
        "                         n_jobs=-1,\n",
        "                         random_state = 42\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuyflxLpsrGh",
        "outputId": "8a8e0974-2a5f-420f-d3b7-10025e06a772"
      },
      "source": [
        "cv_results = cross_validate(estimator=regressor,\n",
        "                            X = new_features_train[feature_cols],\n",
        "                            y = new_features_train['target'],\n",
        "                            scoring=['neg_root_mean_squared_error','r2'],\n",
        "                            cv = outer_cv,\n",
        "                            return_estimator = True,\n",
        "                            verbose = 10\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 40.1min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.691, r2=0.063, total=41.3min\n",
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 41.3min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 41.2min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.717, r2=0.057, total=42.5min\n",
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 83.8min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 42.6min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.805, r2=0.055, total=43.9min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 127.7min remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 127.7min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0JiqfyKuCXC"
      },
      "source": [
        "randomized_search_results = [pd.DataFrame(est.cv_results_) for est in cv_results['estimator']]\n",
        "results = reduce(lambda df1,df2: pd.concat([df1, df2]), randomized_search_results)\n",
        "results.to_csv('randomized_search_run1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "zQQDiJ-OS6Oj",
        "outputId": "9dae55ea-8463-43a0-8cef-d559c8d34871"
      },
      "source": [
        "results.sort_values(by='rank_test_score').head(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>63.538121</td>\n",
              "      <td>3.933666</td>\n",
              "      <td>1.261992</td>\n",
              "      <td>0.192899</td>\n",
              "      <td>0.120606</td>\n",
              "      <td>52</td>\n",
              "      <td>64</td>\n",
              "      <td>{'max_features': 0.1206064345328208, 'min_samp...</td>\n",
              "      <td>-3.662601</td>\n",
              "      <td>-3.763958</td>\n",
              "      <td>-3.705771</td>\n",
              "      <td>-3.710777</td>\n",
              "      <td>0.041530</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>59.890854</td>\n",
              "      <td>5.450841</td>\n",
              "      <td>1.276029</td>\n",
              "      <td>0.165412</td>\n",
              "      <td>0.120606</td>\n",
              "      <td>52</td>\n",
              "      <td>64</td>\n",
              "      <td>{'max_features': 0.1206064345328208, 'min_samp...</td>\n",
              "      <td>-3.806209</td>\n",
              "      <td>-3.752684</td>\n",
              "      <td>-3.734568</td>\n",
              "      <td>-3.764487</td>\n",
              "      <td>0.030415</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>62.268367</td>\n",
              "      <td>6.202222</td>\n",
              "      <td>1.320536</td>\n",
              "      <td>0.187639</td>\n",
              "      <td>0.120606</td>\n",
              "      <td>52</td>\n",
              "      <td>64</td>\n",
              "      <td>{'max_features': 0.1206064345328208, 'min_samp...</td>\n",
              "      <td>-3.724277</td>\n",
              "      <td>-3.723223</td>\n",
              "      <td>-3.809158</td>\n",
              "      <td>-3.752219</td>\n",
              "      <td>0.040264</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32.834480</td>\n",
              "      <td>0.336199</td>\n",
              "      <td>0.636317</td>\n",
              "      <td>0.010143</td>\n",
              "      <td>0.129975</td>\n",
              "      <td>89</td>\n",
              "      <td>33</td>\n",
              "      <td>{'max_features': 0.12997491581800288, 'min_sam...</td>\n",
              "      <td>-3.811856</td>\n",
              "      <td>-3.766749</td>\n",
              "      <td>-3.742039</td>\n",
              "      <td>-3.773548</td>\n",
              "      <td>0.028905</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35.463585</td>\n",
              "      <td>0.136032</td>\n",
              "      <td>0.705475</td>\n",
              "      <td>0.010742</td>\n",
              "      <td>0.129975</td>\n",
              "      <td>89</td>\n",
              "      <td>33</td>\n",
              "      <td>{'max_features': 0.12997491581800288, 'min_sam...</td>\n",
              "      <td>-3.663979</td>\n",
              "      <td>-3.767544</td>\n",
              "      <td>-3.707198</td>\n",
              "      <td>-3.712907</td>\n",
              "      <td>0.042472</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33.734524</td>\n",
              "      <td>0.665576</td>\n",
              "      <td>0.684229</td>\n",
              "      <td>0.012196</td>\n",
              "      <td>0.129975</td>\n",
              "      <td>89</td>\n",
              "      <td>33</td>\n",
              "      <td>{'max_features': 0.12997491581800288, 'min_sam...</td>\n",
              "      <td>-3.724198</td>\n",
              "      <td>-3.730260</td>\n",
              "      <td>-3.813594</td>\n",
              "      <td>-3.756018</td>\n",
              "      <td>0.040788</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "9      63.538121      3.933666  ...        0.041530                1\n",
              "9      59.890854      5.450841  ...        0.030415                1\n",
              "9      62.268367      6.202222  ...        0.040264                1\n",
              "2      32.834480      0.336199  ...        0.028905                2\n",
              "2      35.463585      0.136032  ...        0.042472                2\n",
              "2      33.734524      0.665576  ...        0.040788                2\n",
              "\n",
              "[6 rows x 14 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPNzJVu-Zv1G"
      },
      "source": [
        "### Permutation feature importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j44WqWm-aFmh"
      },
      "source": [
        "After an initial run of hyperparameter tuning a base model is decided upon to check the feature importance. It will be verified if removing the least important features improves scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7V6-jeYZ0GV",
        "outputId": "f9a22ad2-a6e9-45a4-bbcf-8d90f22a58ff"
      },
      "source": [
        "# Random-forest regressor is the base model with parameters\n",
        "# n_estimators = 64\n",
        "# min_samples_split = 52\n",
        "# max_features = 0.120606\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_features_train[feature_cols],\n",
        "                                                    new_features_train['target'],\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 42)\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42,\n",
        "                           n_estimators = 64,\n",
        "                           min_samples_split = 52,\n",
        "                           max_features = 0.120606,\n",
        "                           n_jobs = -1).fit(X_train, y_train)\n",
        "\n",
        "print(f'Base score: {mean_squared_error(y_pred=rf.predict(X_test), y_true=y_test, squared=False)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base score: 3.6924899009061973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPagM9I8gGQQ"
      },
      "source": [
        "perm_imp = permutation_importance(rf, X_test, y_test, scoring='neg_root_mean_squared_error', n_repeats=20, n_jobs=-1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiLp4OIQpnT9",
        "outputId": "205d7dc7-86ff-40a1-9831-3d9764131178"
      },
      "source": [
        "perm_imp.importances_mean.argsort()[::-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([34, 69, 39, 15, 94, 31, 36,  1, 23, 68, 72, 70,  0, 37, 74, 79, 73,\n",
              "       21, 78, 38,  2, 16, 71, 33, 24, 32, 17, 35, 28, 67, 30, 22,  3, 42,\n",
              "       46, 77, 26, 20, 18, 52, 83, 75, 58, 40, 29, 82, 25,  5, 48, 54, 81,\n",
              "       56,  7, 76, 66, 19,  9, 92, 27, 64,  4, 51, 11, 85, 59, 53, 91, 80,\n",
              "       60, 49, 57, 10,  6, 55, 43, 14, 84, 93, 47, 86, 12, 63,  8, 61, 89,\n",
              "       44, 90, 50, 13, 87, 88, 45, 62, 41, 65])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RDDkDi6q2rJ"
      },
      "source": [
        "feature_importance_table = pd.DataFrame()\n",
        "feature_importance_table['feature_names'] = X_test.columns[perm_imp.importances_mean.argsort()[::-1]]\n",
        "feature_importance_table['importance_means'] = perm_imp.importances_mean[perm_imp.importances_mean.argsort()[::-1]]\n",
        "feature_importance_table['importance_std'] = perm_imp.importances_std[perm_imp.importances_mean.argsort()[::-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0md4_ZLZzUpi"
      },
      "source": [
        "num_of_features_dict = {}\n",
        "for x in np.random.randint(low=1, high=89, size=20):\n",
        "\n",
        "  important_features_run1 = feature_importance_table.head(x)['feature_names'].to_numpy()\n",
        "\n",
        "  rf = RandomForestRegressor(random_state=42,\n",
        "                            n_estimators = 64,\n",
        "                            min_samples_split = 52,\n",
        "                            max_features = 0.120606,\n",
        "                            n_jobs = -1).fit(X_train[important_features_run1], y_train)\n",
        "\n",
        "  # print(f'Base score: {mean_squared_error(y_pred=rf.predict(X_test[important_features_run1]), y_true=y_test, squared=False)}')\n",
        "\n",
        "  num_of_features_dict[x] = mean_squared_error(y_pred=rf.predict(X_test[important_features_run1]), y_true=y_test, squared=False)\n",
        "\n",
        "min_score = min(num_of_features_dict.values())\n",
        "best_no_of_features = [key for key in num_of_features_dict if num_of_features_dict[key]==min_score]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOew-6IP6DQJ",
        "outputId": "eee7efaf-4b2b-4cca-beaa-c9faf8753019"
      },
      "source": [
        "best_no_of_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[26]"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Jo36z-5oC4"
      },
      "source": [
        "most_important_features = feature_importance_table.head(26)['feature_names'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgwpy02n6dTd"
      },
      "source": [
        "### Hyperparameter tuning post permutation importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njbSQwDs9EK_",
        "outputId": "c1304a62-c020-4ba5-ab9c-60f4a0e655a8"
      },
      "source": [
        "# Block for randomized grid search using random forest regressor\n",
        "# nested cv for test set performance estimation\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "param_grid = {'n_estimators': randint(40,80),\n",
        "              'min_samples_split': randint(20,80),\n",
        "              'max_features': uniform(0.1,0.75)\n",
        "              }\n",
        "\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "regressor = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=10, cv=inner_cv, \n",
        "                         scoring='neg_root_mean_squared_error', \n",
        "                         verbose=1,\n",
        "                         n_jobs=-1,\n",
        "                         )\n",
        "\n",
        "cv_results = cross_validate(estimator=regressor,\n",
        "                            X = new_features_train[most_important_features],\n",
        "                            y = new_features_train['target'],\n",
        "                            scoring=['neg_root_mean_squared_error','r2'],\n",
        "                            cv = outer_cv,\n",
        "                            return_estimator = True,\n",
        "                            verbose = 10\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 28.1min finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.655, r2=0.057, total=29.5min\n",
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 29.5min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 20.8min finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.755, r2=0.071, total=21.7min\n",
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 51.2min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 23.0min finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.714, r2=0.065, total=23.6min\n",
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 74.9min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 27.5min finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.743, r2=0.050, total=28.4min\n",
            "[CV]  ................................................................\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 103.2min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 28.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] ... , neg_root_mean_squared_error=-3.791, r2=0.060, total=29.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 132.3min remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 132.3min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twn_dnzx6Vfn"
      },
      "source": [
        "randomized_search_results_2 = [pd.DataFrame(est.cv_results_) for est in cv_results['estimator']]\n",
        "results_2 = reduce(lambda df1,df2: pd.concat([df1, df2]), randomized_search_results_2)\n",
        "results_2.to_csv('randomized_search_run2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "po27frdvy1KT",
        "outputId": "5fbf01a0-17ed-40f6-96d3-56f34856ba1a"
      },
      "source": [
        "results_2[results_2.rank_test_score == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>78.668387</td>\n",
              "      <td>0.481345</td>\n",
              "      <td>1.217696</td>\n",
              "      <td>0.020773</td>\n",
              "      <td>0.373834</td>\n",
              "      <td>66</td>\n",
              "      <td>68</td>\n",
              "      <td>{'max_features': 0.3738341495432007, 'min_samp...</td>\n",
              "      <td>-3.763138</td>\n",
              "      <td>-3.759884</td>\n",
              "      <td>-3.728812</td>\n",
              "      <td>-3.750611</td>\n",
              "      <td>0.015472</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49.964921</td>\n",
              "      <td>0.302329</td>\n",
              "      <td>1.207912</td>\n",
              "      <td>0.008157</td>\n",
              "      <td>0.256384</td>\n",
              "      <td>61</td>\n",
              "      <td>67</td>\n",
              "      <td>{'max_features': 0.2563842585276148, 'min_samp...</td>\n",
              "      <td>-3.758239</td>\n",
              "      <td>-3.648364</td>\n",
              "      <td>-3.769161</td>\n",
              "      <td>-3.725254</td>\n",
              "      <td>0.054552</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.949053</td>\n",
              "      <td>0.373637</td>\n",
              "      <td>0.947111</td>\n",
              "      <td>0.028840</td>\n",
              "      <td>0.216518</td>\n",
              "      <td>72</td>\n",
              "      <td>58</td>\n",
              "      <td>{'max_features': 0.21651826361257753, 'min_sam...</td>\n",
              "      <td>-3.719240</td>\n",
              "      <td>-3.674124</td>\n",
              "      <td>-3.805132</td>\n",
              "      <td>-3.732832</td>\n",
              "      <td>0.054340</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43.908508</td>\n",
              "      <td>0.315904</td>\n",
              "      <td>1.112044</td>\n",
              "      <td>0.020875</td>\n",
              "      <td>0.244857</td>\n",
              "      <td>38</td>\n",
              "      <td>58</td>\n",
              "      <td>{'max_features': 0.2448567245464956, 'min_samp...</td>\n",
              "      <td>-3.716940</td>\n",
              "      <td>-3.681936</td>\n",
              "      <td>-3.824484</td>\n",
              "      <td>-3.741120</td>\n",
              "      <td>0.060655</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>30.831943</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.890722</td>\n",
              "      <td>0.023893</td>\n",
              "      <td>0.212713</td>\n",
              "      <td>55</td>\n",
              "      <td>48</td>\n",
              "      <td>{'max_features': 0.21271333525625732, 'min_sam...</td>\n",
              "      <td>-3.739629</td>\n",
              "      <td>-3.652264</td>\n",
              "      <td>-3.772801</td>\n",
              "      <td>-3.721565</td>\n",
              "      <td>0.050840</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "1      78.668387      0.481345  ...        0.015472                1\n",
              "2      49.964921      0.302329  ...        0.054552                1\n",
              "0      33.949053      0.373637  ...        0.054340                1\n",
              "4      43.908508      0.315904  ...        0.060655                1\n",
              "8      30.831943      0.189189  ...        0.050840                1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWj48iysHEOb",
        "outputId": "298908bf-e1df-4ce9-bcaa-3caf57b7ff36"
      },
      "source": [
        "results_2[results_2.rank_test_score == 1].agg(func=np.mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean_fit_time              47.464562\n",
              "std_fit_time                0.332481\n",
              "mean_score_time             1.075097\n",
              "std_score_time              0.020507\n",
              "param_max_features          0.260861\n",
              "param_min_samples_split    58.400000\n",
              "param_n_estimators         59.800000\n",
              "split0_test_score          -3.739437\n",
              "split1_test_score          -3.683314\n",
              "split2_test_score          -3.780078\n",
              "mean_test_score            -3.734277\n",
              "std_test_score              0.047172\n",
              "rank_test_score             1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKe2y0J0lX4C"
      },
      "source": [
        "## Temporary blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiWLyN8k1TIH"
      },
      "source": [
        "# new_features.to_csv('new_features_01102021_03_54.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D26EgIujjQ5x"
      },
      "source": [
        "new_features_train = new_features.merge(train[['card_id','target']], on='card_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL7tEf53uwXk"
      },
      "source": [
        "feature_cols = [x for x in new_features_train.columns if x not in ('card_id','target')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IewAuWpGe-Kx"
      },
      "source": [
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=4, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mw9ylRRfPtf"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KQq4Y0_g02X"
      },
      "source": [
        "param_grid = {'n_estimators': [10, 50],\n",
        "              'min_samples_split': [10, 100],\n",
        "              'max_features': [0.1, 0.5]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhsvaNBUht5T"
      },
      "source": [
        "regressor = GridSearchCV(estimator=rf, param_grid=param_grid, cv=inner_cv, \n",
        "                         scoring='neg_root_mean_squared_error', \n",
        "                         verbose=7,\n",
        "                         n_jobs=-1\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IbqNUmx2aBf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_features_train[feature_cols],\n",
        "                                                    new_features_train['target'],\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2EWhRegiGo9"
      },
      "source": [
        "# cv_results = cross_validate(estimator=regressor,\n",
        "#                             X = new_features_train[feature_cols],\n",
        "#                             y = new_features_train['target'],\n",
        "#                             scoring=['neg_root_mean_squared_error','r2'],\n",
        "#                             cv = outer_cv,\n",
        "#                             return_estimator = True,\n",
        "#                             verbose = 4\n",
        "#                             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGt_mMq1wA6b",
        "outputId": "4b227605-cd8c-446d-9e2e-6284e312a0ba"
      },
      "source": [
        "regressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 19.1min finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
              "                                             criterion='mse', max_depth=None,\n",
              "                                             max_features='auto',\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             max_samples=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             n_estimators=100, n_jobs=None,\n",
              "                                             oob_score=False, random_state=42,\n",
              "                                             verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'max_features': [0.1, 0.5],\n",
              "                         'min_samples_split': [10, 100],\n",
              "                         'n_estimators': [10, 50]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_root_mean_squared_error', verbose=7)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRGuwiTY33VP"
      },
      "source": [
        "pd.DataFrame(regressor.cv_results_).to_csv('grid_search_1_test_3_691.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZw_Za8g96rC",
        "outputId": "729af395-f226-4307-cf25-313413a9917f"
      },
      "source": [
        "regressor.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-3.6914373922927317"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdpe3hstEiME"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=42, max_features=0.1, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyDsDNfVCXFW"
      },
      "source": [
        "param_grid_2 = {'n_estimators': [50, 75, 100],\n",
        "              'min_samples_split': [20, 60, 100]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trqgylSjEWd2"
      },
      "source": [
        "regressor2 = GridSearchCV(estimator=rf, param_grid=param_grid_2, cv=inner_cv, \n",
        "                         scoring='neg_root_mean_squared_error', \n",
        "                         verbose=3,\n",
        "                         n_jobs=-1\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km2JeEMNEyx8"
      },
      "source": [
        "regressor2.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "JQKvI3AHFRd0",
        "outputId": "08e5e936-dbd9-4ccc-c06c-955e190dc8ec"
      },
      "source": [
        "pd.DataFrame(regressor2.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50.102673</td>\n",
              "      <td>0.079331</td>\n",
              "      <td>1.348845</td>\n",
              "      <td>0.007483</td>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "      <td>{'min_samples_split': 20, 'n_estimators': 50}</td>\n",
              "      <td>-3.746382</td>\n",
              "      <td>-3.828751</td>\n",
              "      <td>-3.745015</td>\n",
              "      <td>-3.773382</td>\n",
              "      <td>0.039155</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>75.054831</td>\n",
              "      <td>0.215345</td>\n",
              "      <td>1.994313</td>\n",
              "      <td>0.015168</td>\n",
              "      <td>20</td>\n",
              "      <td>75</td>\n",
              "      <td>{'min_samples_split': 20, 'n_estimators': 75}</td>\n",
              "      <td>-3.741628</td>\n",
              "      <td>-3.819369</td>\n",
              "      <td>-3.736971</td>\n",
              "      <td>-3.765989</td>\n",
              "      <td>0.037793</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101.096685</td>\n",
              "      <td>0.491589</td>\n",
              "      <td>2.694486</td>\n",
              "      <td>0.016525</td>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>{'min_samples_split': 20, 'n_estimators': 100}</td>\n",
              "      <td>-3.738336</td>\n",
              "      <td>-3.814844</td>\n",
              "      <td>-3.734771</td>\n",
              "      <td>-3.762650</td>\n",
              "      <td>0.036935</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.308520</td>\n",
              "      <td>0.175031</td>\n",
              "      <td>1.172060</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>{'min_samples_split': 60, 'n_estimators': 50}</td>\n",
              "      <td>-3.740070</td>\n",
              "      <td>-3.811979</td>\n",
              "      <td>-3.736291</td>\n",
              "      <td>-3.762780</td>\n",
              "      <td>0.034823</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.807988</td>\n",
              "      <td>0.112114</td>\n",
              "      <td>1.689348</td>\n",
              "      <td>0.039349</td>\n",
              "      <td>60</td>\n",
              "      <td>75</td>\n",
              "      <td>{'min_samples_split': 60, 'n_estimators': 75}</td>\n",
              "      <td>-3.733617</td>\n",
              "      <td>-3.810776</td>\n",
              "      <td>-3.733795</td>\n",
              "      <td>-3.759396</td>\n",
              "      <td>0.036331</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>87.697334</td>\n",
              "      <td>0.264262</td>\n",
              "      <td>2.271882</td>\n",
              "      <td>0.043184</td>\n",
              "      <td>60</td>\n",
              "      <td>100</td>\n",
              "      <td>{'min_samples_split': 60, 'n_estimators': 100}</td>\n",
              "      <td>-3.733422</td>\n",
              "      <td>-3.808130</td>\n",
              "      <td>-3.731486</td>\n",
              "      <td>-3.757679</td>\n",
              "      <td>0.035683</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40.873047</td>\n",
              "      <td>0.039518</td>\n",
              "      <td>1.074902</td>\n",
              "      <td>0.004148</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>{'min_samples_split': 100, 'n_estimators': 50}</td>\n",
              "      <td>-3.736287</td>\n",
              "      <td>-3.815146</td>\n",
              "      <td>-3.735208</td>\n",
              "      <td>-3.762214</td>\n",
              "      <td>0.037432</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>61.267514</td>\n",
              "      <td>0.242280</td>\n",
              "      <td>1.593149</td>\n",
              "      <td>0.009854</td>\n",
              "      <td>100</td>\n",
              "      <td>75</td>\n",
              "      <td>{'min_samples_split': 100, 'n_estimators': 75}</td>\n",
              "      <td>-3.730248</td>\n",
              "      <td>-3.812198</td>\n",
              "      <td>-3.732140</td>\n",
              "      <td>-3.758195</td>\n",
              "      <td>0.038193</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>78.419926</td>\n",
              "      <td>4.881121</td>\n",
              "      <td>1.904553</td>\n",
              "      <td>0.264015</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>{'min_samples_split': 100, 'n_estimators': 100}</td>\n",
              "      <td>-3.728652</td>\n",
              "      <td>-3.809745</td>\n",
              "      <td>-3.730146</td>\n",
              "      <td>-3.756181</td>\n",
              "      <td>0.037881</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0      50.102673      0.079331  ...        0.039155                9\n",
              "1      75.054831      0.215345  ...        0.037793                8\n",
              "2     101.096685      0.491589  ...        0.036935                6\n",
              "3      44.308520      0.175031  ...        0.034823                7\n",
              "4      65.807988      0.112114  ...        0.036331                4\n",
              "5      87.697334      0.264262  ...        0.035683                2\n",
              "6      40.873047      0.039518  ...        0.037432                5\n",
              "7      61.267514      0.242280  ...        0.038193                3\n",
              "8      78.419926      4.881121  ...        0.037881                1\n",
              "\n",
              "[9 rows x 13 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTmoYm7HJgXz",
        "outputId": "4f69cd3a-60c7-4ca7-9cec-0384860b9074"
      },
      "source": [
        "regressor2.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.9s finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "-3.6872325616079693"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw50ntlbLLnp"
      },
      "source": [
        "param_grid_3 = {'min_samples_split': randint(200,400)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJa3cvIsLPKo"
      },
      "source": [
        "rf = RandomForestRegressor(random_state=42, max_features=0.1, n_estimators=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaGAULf4Ldxy"
      },
      "source": [
        "regressor3 = RandomizedSearchCV(estimator=rf, param_distributions=param_grid_3, n_iter=10, cv=inner_cv, \n",
        "                         scoring='neg_root_mean_squared_error', \n",
        "                         verbose=3,\n",
        "                         n_jobs=-1\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlSH01OzLmdu",
        "outputId": "31f8ef56-e2f3-4264-e11a-73a09ee47b7f"
      },
      "source": [
        "regressor3.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.3min finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=KFold(n_splits=3, random_state=42, shuffle=True),\n",
              "                   error_score=nan,\n",
              "                   estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                   ccp_alpha=0.0,\n",
              "                                                   criterion='mse',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features=0.1,\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n...=100,\n",
              "                                                   n_jobs=None, oob_score=False,\n",
              "                                                   random_state=42, verbose=1,\n",
              "                                                   warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa2c4987e90>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False,\n",
              "                   scoring='neg_root_mean_squared_error', verbose=3)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "4cIcyNhbLvlP",
        "outputId": "fdaccf87-9c3c-48f7-bde7-7dc96258becd"
      },
      "source": [
        "pd.DataFrame(regressor3.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64.163149</td>\n",
              "      <td>0.236754</td>\n",
              "      <td>1.494110</td>\n",
              "      <td>0.021608</td>\n",
              "      <td>386</td>\n",
              "      <td>{'min_samples_split': 386}</td>\n",
              "      <td>-3.733880</td>\n",
              "      <td>-3.812780</td>\n",
              "      <td>-3.734129</td>\n",
              "      <td>-3.760263</td>\n",
              "      <td>0.037135</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65.017420</td>\n",
              "      <td>0.073118</td>\n",
              "      <td>1.537872</td>\n",
              "      <td>0.003923</td>\n",
              "      <td>368</td>\n",
              "      <td>{'min_samples_split': 368}</td>\n",
              "      <td>-3.733210</td>\n",
              "      <td>-3.812068</td>\n",
              "      <td>-3.734012</td>\n",
              "      <td>-3.759763</td>\n",
              "      <td>0.036986</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70.534903</td>\n",
              "      <td>0.249769</td>\n",
              "      <td>1.685256</td>\n",
              "      <td>0.027595</td>\n",
              "      <td>247</td>\n",
              "      <td>{'min_samples_split': 247}</td>\n",
              "      <td>-3.728990</td>\n",
              "      <td>-3.811120</td>\n",
              "      <td>-3.730169</td>\n",
              "      <td>-3.756760</td>\n",
              "      <td>0.038441</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69.316227</td>\n",
              "      <td>0.177451</td>\n",
              "      <td>1.619207</td>\n",
              "      <td>0.011331</td>\n",
              "      <td>267</td>\n",
              "      <td>{'min_samples_split': 267}</td>\n",
              "      <td>-3.730419</td>\n",
              "      <td>-3.811062</td>\n",
              "      <td>-3.730926</td>\n",
              "      <td>-3.757469</td>\n",
              "      <td>0.037897</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64.581584</td>\n",
              "      <td>0.119427</td>\n",
              "      <td>1.457651</td>\n",
              "      <td>0.005407</td>\n",
              "      <td>397</td>\n",
              "      <td>{'min_samples_split': 397}</td>\n",
              "      <td>-3.734061</td>\n",
              "      <td>-3.811470</td>\n",
              "      <td>-3.733983</td>\n",
              "      <td>-3.759838</td>\n",
              "      <td>0.036509</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>64.750549</td>\n",
              "      <td>0.437569</td>\n",
              "      <td>1.514983</td>\n",
              "      <td>0.011333</td>\n",
              "      <td>384</td>\n",
              "      <td>{'min_samples_split': 384}</td>\n",
              "      <td>-3.733774</td>\n",
              "      <td>-3.813239</td>\n",
              "      <td>-3.733023</td>\n",
              "      <td>-3.760012</td>\n",
              "      <td>0.037638</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>64.248586</td>\n",
              "      <td>0.201700</td>\n",
              "      <td>1.499857</td>\n",
              "      <td>0.014153</td>\n",
              "      <td>390</td>\n",
              "      <td>{'min_samples_split': 390}</td>\n",
              "      <td>-3.733250</td>\n",
              "      <td>-3.813379</td>\n",
              "      <td>-3.731636</td>\n",
              "      <td>-3.759421</td>\n",
              "      <td>0.038159</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>72.754632</td>\n",
              "      <td>0.110083</td>\n",
              "      <td>1.746888</td>\n",
              "      <td>0.023665</td>\n",
              "      <td>209</td>\n",
              "      <td>{'min_samples_split': 209}</td>\n",
              "      <td>-3.728775</td>\n",
              "      <td>-3.811714</td>\n",
              "      <td>-3.730773</td>\n",
              "      <td>-3.757087</td>\n",
              "      <td>0.038636</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>70.811274</td>\n",
              "      <td>0.431427</td>\n",
              "      <td>1.704079</td>\n",
              "      <td>0.016762</td>\n",
              "      <td>239</td>\n",
              "      <td>{'min_samples_split': 239}</td>\n",
              "      <td>-3.729289</td>\n",
              "      <td>-3.811064</td>\n",
              "      <td>-3.729978</td>\n",
              "      <td>-3.756777</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>65.084155</td>\n",
              "      <td>0.680013</td>\n",
              "      <td>1.379958</td>\n",
              "      <td>0.229447</td>\n",
              "      <td>350</td>\n",
              "      <td>{'min_samples_split': 350}</td>\n",
              "      <td>-3.731970</td>\n",
              "      <td>-3.812888</td>\n",
              "      <td>-3.734580</td>\n",
              "      <td>-3.759813</td>\n",
              "      <td>0.037545</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0      64.163149      0.236754  ...        0.037135               10\n",
              "1      65.017420      0.073118  ...        0.036986                6\n",
              "2      70.534903      0.249769  ...        0.038441                1\n",
              "3      69.316227      0.177451  ...        0.037897                4\n",
              "4      64.581584      0.119427  ...        0.036509                8\n",
              "5      64.750549      0.437569  ...        0.037638                9\n",
              "6      64.248586      0.201700  ...        0.038159                5\n",
              "7      72.754632      0.110083  ...        0.038636                3\n",
              "8      70.811274      0.431427  ...        0.038388                2\n",
              "9      65.084155      0.680013  ...        0.037545                7\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OES6RwxiLytc",
        "outputId": "2bfbfc99-9d70-421f-87f2-64ecb0081768"
      },
      "source": [
        "regressor3.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "-3.6912524680416885"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJqUJRXhL9H-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}